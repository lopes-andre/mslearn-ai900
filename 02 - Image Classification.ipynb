{"cells":[{"cell_type":"markdown","source":["# Classificação de Imagem\n","\n","O Serviço Cognitivo ***Computer Vision*** fornece modelos pré-construídos úteis para trabalhar com imagens, mas você vai ter que, com certa frequência, treinar o seu próprio modelo de visão computacional. Por exemplo, suponha que a empresa Northwind Traders quer criar um sistema de pagamento automático nas suas lojas que identifique os produtos que os clientes estão comprando se baseando em uma imagem capturada por uma câmera posicionada próxima ao caixa da loja. Para fazer isso, você terá que treinar um modelo de classificação de imagem que possa classificar as imagems para identificar os itens sendo comprados.\n","\n","![Um robô segurando uma prancheta, classificando imagens de uma maçã, uma banana e uma laranja](./images/image-classification.jpg)\n","\n","No Azure, você pode usar o serviço cognitivo ***Custom Vision*** para treinar um modelo baseado em imagens existentes. Há dois elementos na criação de uma solução de classificação de imagem. Primeiro, você precisa treinar um modelo para reconhecer diferentes classes usando imagens existentes. Então, quando o modelo estiver treinado, você precisa publicar o modelo como serviço para poder ser consumido pela sua aplicação.\n","\n","## Crie um recurso de Custom Vision\n","\n","TPara usar o serviço de ***Custom Vision*** (Visão Customizada), você precisa de um recurso Azure que você pode usar para **treinar** o modelo e um recurso com o qual você pode **publicar** o modelo para a sua aplicação poder usar. O recurso para cada tarefa (ou ambas) pode ser um recurso ***Cognitive Services*** genérico, ou um recurso específico de ***Custom Vision***. Você pode usar o mesmo recurso de Serviço Cognitivo para cada uma destas tarefas, ou você pode usar recursos diferentes (na mesma região) para cada tarefa para gerenciar os custos separadamente.\n","\n","Siga as instruções a seguir para criar um novo recurso de ***Custom Vision***.\n","\n","1. Em uma aba do seu navegador, abra o portal do Azure em [https://portal.azure.com](https://portal.azure.com), e faça login com a sua conta Microsfot associada à sua assinatura Azure.\n","2. Selecione o botão ***&#65291;Create a resource***, pesquise por *custom vision*, e crie um recurso ***Custom Vision*** com as seguintes configurações:\n","    - **Create options**: Ambas\n","    - **Subscription**: *Sua assinatura Azure*\n","    - **Resource group**: *Selecione um resource group ou crie um com nome único*\n","    - **Name**: *Entre um nome único*\n","    - **Training location**: *Selecione qualquer região disponível*\n","    - **Training pricing tier**: F0\n","    - **Prediction location**: *A mesma região da **Training Location***\n","    - **Prediction pricing tier**: F0\n","\n","    > **Nota**: Se você já tiver um serviço de *Custom Vision* F0 na sua assinatura, selecione **S0** para este serviço.\n","\n","3. Espere até que os recursos sejam criados, e note que dois recursos de ***Custom Vision*** são disponibilizados; um para treinamento e outro para predição. Você pode visualizá-los navegando até o *resource group* onde você criou eles.\n","\n","## Crie um projeto de ***Custom Vision***\n","\n","Para treinar um modelo de detecção de objetos, você precisa criar um projeto de ***Custom Vision*** baseado no seu recurso de treinamento. Para fazer isso, você vai precisar usar o portal ***Custom Vision***.\n","\n","1. Baixe e extraia as imagens de treinamento do link https://aka.ms/fruit-images.\n","2. Em outra aba do navegador, abra o portal ***Custom Vision*** em [https://customvision.ai](https://customvision.ai). Se questionado, entre com a sua conta Microsoft associada com a sua assinatura Azure e concorde com os termos de serviço.\n","3. No portal ***Custom Vision***, crie um novo projeto com as configurações a seguir:\n","    - **Name**: *Grocery Checkout* (ou *Pagamento de Compras*, caso prefira em português)\n","    - **Description**: Classificação de imagem para compras\n","    - **Resource**: *O recurso de Custom Vision que você criou anteriormente*\n","    - **Project Types**: *Classification* (Classificação)\n","    - **Classification Types**: *Multiclass (single tag per image)* (Multiclasse (etiqueta única por imagem))\n","    - **Domains**: *Food* (Comida)\n","4. Clique em **\\[+\\] Add images**, e selecione todos os arquivos na pasta **apple** que você extraiu anteriormente. Então faça upload dos arquivos de imagem e especifique a tag *apple* (ou *maçã*, se você preferir manter em português), assim:\n","\n","![Upload de uma maça com a tag apple](./images/upload_apples.jpg)\n","   \n","5. Repita os passos anteriores para enviar as imagens na pasta **banana** com a tag *banana*, e as imagens na pasta **orange** com a tag *orange* (ou *laranja*, caso prefira).\n","6. Explore as imagens que você enviou no projeto de ***Custom Vision*** - deve haver 15 imagens de cada classe, assim:\n","\n","![Imagens das frutas classificadas - 15 maçãs, 15 bananas, and 15 laranjas](./images/fruit.jpg)\n","    \n","7. No projeto ***Custom Vision***, acima das imagens, treine o modelo de classificação usando as imagens etiquetadas cliando em **Train**. Selecione a opção **Quick Training**, e então espere até que a iteração de treinamento esteja completa (isso pode levar alguns minutos).\n","8. Quando a iteração do modelo tiver sido treinada, revise as métricas de *Precision*, *Recall* e *AP* - elas medem a precisão do modelo de classificação, todas devem ser altas.\n","\n","## Teste o modelo\n","\n","Antes de publicar essa iteração do modelo para a sua aplicação utlizar, você deve testá-lo.\n","\n","1. Acima das métricas de performance, clique em ***Quick Test***.\n","2. Na caixa ***Image URL***, digite `https://aka.ms/apple-image` e clique &#10132;\n","3. Veja as predições retornadas pelo seu modelo - a classificação de probabilidade para *maçã* deve ser a mais alta, assim:\n","\n","![Uma imagem de com a predição de classe de uma maçã](./images/test-apple.jpg)\n","\n","4. Feche a janela do ***Quick Test***.\n","\n","## Publique e consuma o modelo de classificação de imagem\n","\n","Agora você está pronto para publicar o seu modelo treinado e para usá-lo por uma aplicação cliente.\n","\n","9. Clique em **&#128504; Publish** para publicar o modelo treinado com as configurações a seguir:\n","    - **Model name**: *groceries* (ou  *compras* caso queira manter em português)\n","    - **Prediction Resource**: *O recurso de predicão que você criou anteriormente*.\n","\n","### (!) Verifique \n","Você usou o mesmo nome do modelo: **groceries**?   \n","\n","10. Após publicar, clique no ícone *settings* (&#9881; Configurações) na parte superior direita da página de **Performance** para ver as configurações do projeto. Então, sob  **General** (na esquerda), copie o **Project Id** (Id do Projeto). Role este notebook para baixo e cole o Id do Projeto na célular de código abaixo do passo 13 substituindo  **ID_DO_PROJETO**.\n","\n","![Project ID nas configurações do projeto](./images/cv_project_settings.jpg)\n","\n","> _**Nota**: Caso você tenha usado o recurso **Cognitive Services** ao invés de criar um recurso **Custom Vision** no comeo deste exercício, você pode copiar a sua chave e endpoint do lado direito das configurações do seu projeto, colar isso na célula de código abaixo, e rodar para ver os resultados. Caso contrário, continue completando os passos abaixo para pegar a chave e endpoint para o seu recurso de predição Custom Vision._\n","\n","11. Na parte superior esquerda da página **Project Settings**, clique no ícone *Projects Gallery* (&#128065;) para retornar à página inicial do portal ***Custom Vision***, onde o seu projeto agora está listado.\n","\n","12. Na página inicial do portal ***Custom Vision***, na parte superior direita, clique no ícone *settings* (&#9881; Configurações) para visualizar as configurações do seu serviço ***Custom Vision***. Então, sob **Resources**, expanda o recurso **prediction** (<u>não</u> o recurso de treinamento) e copie os valores da sua **Key** (Chave) e **Endpoint** e cole na célula de código abaixo do passo 13, substituindo **SUA_CHAVE** e **SEU_ENDPOINT**.\n","\n","### (!) Verifique\n","Se você estiver usando um recurso ***Custom Vision***, você usou o recurso ***prediction*** (<u>não</u> o recurso de treinamento)?\n","\n","![Chave e Endpoint do recurso de predição nas configurações de Custom Vision](./images/cv_settings.jpg)\n","\n","13. Rode a célula de código abaixo clicando no botão **Run cell** (&#9655;) (à esquerda da célular) para configurar as variáveis com os valores do id do seu projeto, chave e o endpoint."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["project_id = 'ID_DO_PROJETO'\n","cv_key = 'SUA_CHAVE'\n","cv_endpoint = 'SEU_ENDPOINT'\n","\n","model_name = 'groceries' # esse valor deve ser idêntico ao nome do modelo de quando você publica a iteração do seu modelo (é case-sensitive)\n","print('Pronto para fazer predição usando o modelo {} no projeto {}'.format(model_name, project_id))"],"outputs":[],"metadata":{"gather":{"logged":1599691949340}}},{"cell_type":"markdown","source":["Agora você pode usar sua chave e endpoint como um cliente ***Custom Vision*** para conectar ao seu modelo de classificação.model.\n","\n","Rode a célula de código a seguir para classificar uma seleção de imagens de teste usando o seu modelo publicado.\n","\n","> **Nota**: Não se precoupe muito com os detalhes do código. Ele usa a SDK de Computer Vision para Python para pegar uma classe de predição para cada imagem na pasta /data/image-classification/test-fruit ."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n","from msrest.authentication import ApiKeyCredentials\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import os\n","%matplotlib inline\n","\n","# Pega as imagens de teste na pasta data/image-classification/test-fruit\n","test_folder = os.path.join('data', 'image-classification', 'test-fruit')\n","test_images = os.listdir(test_folder)\n","\n","# Cria uma instância do serviço de predição\n","credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n","custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\n","\n","# Cria uma figura para exibir os resultados\n","fig = plt.figure(figsize=(16, 8))\n","\n","# Pega as imagens e exibe as classes para cada uma\n","print('Classificando as imagens em {} ...'.format(test_folder))\n","for i in range(len(test_images)):\n","    # Abre a imagem e usa o modelo de Custom Vision para classificá-la\n","    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n","    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n","    # Os resultados incluem a probabilidade para cada tag, em ordem descendente de probabilidade - pega a primeira\n","    prediction = classification.predictions[0].tag_name\n","    # Exibe a imagem com a sua classe mais provável\n","    img = Image.open(os.path.join(test_folder, test_images[i]))\n","    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n","    a.axis('off')\n","    imgplot = plt.imshow(img)\n","    a.set_title(prediction)\n","plt.show()"],"outputs":[],"metadata":{"gather":{"logged":1599692327514}}},{"cell_type":"markdown","source":["Muito provavelmente o seu modelo de classificação de imagem identificou corretamente as compras nas imagens.\n","\n","## Saiba mais\n","\n","O serviço ***Custom Vision*** oferece mais capacidades do que exploramos neste exercício. Por exemplo, você pode também usar o serviço de ***Custom Vision*** para criar modelos de *Deteção de Objetos*; que não apenas classificam objetos em imagens, mas também retornam *bounding boxes* (caixas de contorno) que mostram a localização do objeto na imagem.\n","\n","Para saber mais sobre o serviço cognitivo ***Custom Vision***, veja a [documentação do Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)"],"metadata":{}}],"metadata":{"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"kernel_info":{"name":"python3-azureml"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}